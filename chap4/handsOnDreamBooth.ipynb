{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初见DreamBooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eae4afb54794fa5af4620eb2fcaffad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 登录到hugging face hub\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(x):\n",
    "    x = x * 0.5 + 0.5\n",
    "    grid = torchvision.utils.make_grid(x)\n",
    "    grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255\n",
    "    grid_im = Image.fromarray(grid_im.numpy().astype(np.uint8))\n",
    "    return grid_im\n",
    "def make_grid(images,size=64):\n",
    "    output_im = Image.new(\"RGB\", (size* len(images), size))\n",
    "    for i, im in enumerate(images):\n",
    "        output_im.paste(\n",
    "            im.resize((size,size),(1 * size,0))\n",
    "        )\n",
    "    return output_im\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载SD管线\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载SD模型\n",
    "model_id = \"sd-dreambooth-library/mr-potato-head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mr-potato-head'...\n",
      "remote: Enumerating objects: 42, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 42 (delta 0), reused 2 (delta 0), pack-reused 39\u001b[K\n",
      "Unpacking objects: 100% (42/42), 632.93 KiB | 2.85 MiB/s, done.\n",
      "Downloading safety_checker/pytorch_model.bin (608 MB)\n",
      "Downloading text_encoder/pytorch_model.bin (246 MB)\n",
      "Downloading unet/diffusion_pytorch_model.bin (1.7 GB)s\n",
      "Downloading vae/diffusion_pytorch_model.bin (167 MB)  \n",
      "Filtering content: 100% (4/4), 2.55 GiB | 1.94 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# 克隆模型\n",
    "!git clone https://huggingface.co/$model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "safety_checker/model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14755c859d1d4508940a5483f66f7da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "LocalEntryNotFoundError",
     "evalue": "Connection error, and we cannot find the requested files in the disk cache. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 加载模型\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m StableDiffusionPipeline\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     model_id,\n\u001b[1;32m      4\u001b[0m     torchdtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16,\n\u001b[1;32m      5\u001b[0m )\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:932\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39m# 1. Download the checkpoints and configs\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[39m# use snapshot download here to get it working from from_pretrained\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(pretrained_model_name_or_path):\n\u001b[0;32m--> 932\u001b[0m     cached_folder \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mdownload(\n\u001b[1;32m    933\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    934\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    935\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    936\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    937\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    938\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    939\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    940\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    941\u001b[0m         from_flax\u001b[39m=\u001b[39;49mfrom_flax,\n\u001b[1;32m    942\u001b[0m         use_safetensors\u001b[39m=\u001b[39;49muse_safetensors,\n\u001b[1;32m    943\u001b[0m         custom_pipeline\u001b[39m=\u001b[39;49mcustom_pipeline,\n\u001b[1;32m    944\u001b[0m         custom_revision\u001b[39m=\u001b[39;49mcustom_revision,\n\u001b[1;32m    945\u001b[0m         variant\u001b[39m=\u001b[39;49mvariant,\n\u001b[1;32m    946\u001b[0m         load_connected_pipeline\u001b[39m=\u001b[39;49mload_connected_pipeline,\n\u001b[1;32m    947\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    948\u001b[0m     )\n\u001b[1;32m    949\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    950\u001b[0m     cached_folder \u001b[39m=\u001b[39m pretrained_model_name_or_path\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1507\u001b[0m, in \u001b[0;36mDiffusionPipeline.download\u001b[0;34m(cls, pretrained_model_name, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[39m# download all allow_patterns - ignore_patterns\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1507\u001b[0m     cached_folder \u001b[39m=\u001b[39m snapshot_download(\n\u001b[1;32m   1508\u001b[0m         pretrained_model_name,\n\u001b[1;32m   1509\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1510\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1511\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1512\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1513\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1514\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1515\u001b[0m         allow_patterns\u001b[39m=\u001b[39;49mallow_patterns,\n\u001b[1;32m   1516\u001b[0m         ignore_patterns\u001b[39m=\u001b[39;49mignore_patterns,\n\u001b[1;32m   1517\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1518\u001b[0m     )\n\u001b[1;32m   1520\u001b[0m     \u001b[39m# retrieve pipeline class from local file\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m     cls_name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mload_config(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cached_folder, \u001b[39m\"\u001b[39m\u001b[39mmodel_index.json\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_class_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py:235\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, repo_type, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class)\u001b[0m\n\u001b[1;32m    233\u001b[0m         _inner_hf_hub_download(file)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     thread_map(\n\u001b[1;32m    236\u001b[0m         _inner_hf_hub_download,\n\u001b[1;32m    237\u001b[0m         filtered_repo_files,\n\u001b[1;32m    238\u001b[0m         desc\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mFetching \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mlen\u001b[39;49m(filtered_repo_files)\u001b[39m}\u001b[39;49;00m\u001b[39m files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    239\u001b[0m         max_workers\u001b[39m=\u001b[39;49mmax_workers,\n\u001b[1;32m    240\u001b[0m         \u001b[39m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[1;32m    241\u001b[0m         tqdm_class\u001b[39m=\u001b[39;49mtqdm_class \u001b[39mor\u001b[39;49;00m hf_tqdm,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrealpath(local_dir))\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m \u001b[39mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m _executor_map(ThreadPoolExecutor, fn, \u001b[39m*\u001b[39;49miterables, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtqdm_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[39m=\u001b[39mlock_name) \u001b[39mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39mwith\u001b[39;00m PoolExecutor(max_workers\u001b[39m=\u001b[39mmax_workers, initializer\u001b[39m=\u001b[39mtqdm_class\u001b[39m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[39m=\u001b[39m(lk,)) \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(tqdm_class(ex\u001b[39m.\u001b[39;49mmap(fn, \u001b[39m*\u001b[39;49miterables, chunksize\u001b[39m=\u001b[39;49mchunksize), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py:211\u001b[0m, in \u001b[0;36msnapshot_download.<locals>._inner_hf_hub_download\u001b[0;34m(repo_file)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inner_hf_hub_download\u001b[39m(repo_file: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m hf_hub_download(\n\u001b[1;32m    212\u001b[0m         repo_id,\n\u001b[1;32m    213\u001b[0m         filename\u001b[39m=\u001b[39;49mrepo_file,\n\u001b[1;32m    214\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    215\u001b[0m         revision\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    216\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    217\u001b[0m         local_dir\u001b[39m=\u001b[39;49mlocal_dir,\n\u001b[1;32m    218\u001b[0m         local_dir_use_symlinks\u001b[39m=\u001b[39;49mlocal_dir_use_symlinks,\n\u001b[1;32m    219\u001b[0m         library_name\u001b[39m=\u001b[39;49mlibrary_name,\n\u001b[1;32m    220\u001b[0m         library_version\u001b[39m=\u001b[39;49mlibrary_version,\n\u001b[1;32m    221\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    222\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    223\u001b[0m         etag_timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m    224\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    225\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    226\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    227\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/hugging/lib/python3.11/site-packages/huggingface_hub/file_download.py:1291\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1286\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot find the requested files in the disk cache and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1287\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m outgoing traffic has been disabled. To enable hf.co look-ups\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1288\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m and downloads online, set \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocal_files_only\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1289\u001b[0m         )\n\u001b[1;32m   1290\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1291\u001b[0m         \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1292\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m the disk cache. Please try again or make sure your Internet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1295\u001b[0m         )\n\u001b[1;32m   1297\u001b[0m \u001b[39m# From now on, etag and commit_hash are not None.\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[39massert\u001b[39;00m etag \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39metag must have been retrieved from server\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: Connection error, and we cannot find the requested files in the disk cache. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torchdtype=torch.float16,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成土豆头\n",
    "prompt = \"an abstract oil painting of sks mr potato by picasso\"\n",
    "image = model(\n",
    "    prompt,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=7.5,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
